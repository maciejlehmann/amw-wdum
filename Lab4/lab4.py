# -*- coding: utf-8 -*-
"""Lab4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nx7icpsGvbnNLUbL0S6KUuQU-d_Dv8vc
"""

import requests
from bs4 import BeautifulSoup
import string
import random
import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gc = gspread.authorize(GoogleCredentials.get_application_default())
sheet = gc.create('Lehmann-175IC')
sheet = gc.open('Lehmann-175IC')

# Giełda

sheet.add_worksheet(rows=6,cols=4, title='Giełda')

sheet_instance = sheet.get_worksheet(1)

sheet_instance.update('A1', 'Spółka')
sheet_instance.update('B1', 'Kurs')
sheet_instance.update('C1', 'Zmiana')
sheet_instance.update('D1', 'Transakcje')


def random_char(y):
    return ''.join(random.choice(string.ascii_lowercase) for x in range(y))


rnd_shortcut = ''
tries = 1
max_tries = 6
while tries < max_tries:
    rnd_shortcut = (random_char(3))
    url = f'https://stooq.pl/q/?s={rnd_shortcut}'
    page = requests.get(url)
    soup = BeautifulSoup(page.text, 'html.parser')
    results = soup.find('span', id=f'aq_{rnd_shortcut}_c2')
    if results != None:
        zmiana = soup.find('span', id=f'aq_{rnd_shortcut}_m2')
        transakcja = soup.find('span', id=f'aq_{rnd_shortcut}_n1')
        sheet_instance.update(f'A{tries + 1}', rnd_shortcut)
        sheet_instance.update(f'B{tries + 1}', zmiana.text)
        sheet_instance.update(f'C{tries + 1}', results.text)
        sheet_instance.update(f'D{tries + 1}', transakcja.text)
        tries += 1
        rnd_shortcut = ''

# Linki

sheet.add_worksheet(rows=150, cols=1, title='Linki')
link_instance = sheet.get_worksheet(2)
url= 'https://naekranie.pl/'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')
i = 1
for link in soup.find_all('a'):
    reLink = link.get('href')
    try:
        reLink = link.get('href')
        if(reLink[0] != '/' and reLink[0] != "#" and reLink[0] != "?" and len(reLink) > 3):
            link_instance.update(f'A{i}', reLink)
            i += 1
    except TypeError:
        pass

# Filmweb

sheet.add_worksheet(rows=2, cols=4, title='Filmweb')
filmweb_instance = sheet.get_worksheet(3)
filmweb_instance.update('A1', 'Reżyser')
filmweb_instance.update('B1', 'Boxoffice')
filmweb_instance.update('C1', 'Ocena')
filmweb_instance.update('D1', 'Data premiery')
url= 'https://www.filmweb.pl/film/Avengers%3A+Koniec+gry-2019-790542'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')
director = soup.find('span', itemprop ='name')
filmweb_instance.update('A2', director.text)
boxoffice_section = soup.find('div', class_='filmOtherInfoSection__group')
boxoffice = boxoffice_section.find('div', class_='filmInfo__info')
filmweb_instance.update('B2', boxoffice.text)
rating = soup.find('span', class_='filmRating__rateValue')
filmweb_instance.update("C2", rating.text)
base = 'https://www.filmweb.pl'
idxStart = len(base)
splitUrl = f'{url[idxStart:]}/dates'
release = soup.find('a', href=splitUrl)
filmweb_instance.update('D2', release.text)