{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBPhZSxc2sJPH+Py97qnUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maciejlehmann/amw-wdum/blob/main/Lab5/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVVVQz6PJuRi"
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "import textacy"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXDUJvyIKFBz",
        "outputId": "369322aa-c4a3-48cb-82ea-6eed9609b3fd"
      },
      "source": [
        "# Czytanie ze stringa\n",
        "\n",
        "introduction_text = ('To jest tutorial petwarzania naturalnych języków w Spacy.')\n",
        "introduction_doc = nlp(introduction_text)\n",
        "\n",
        "print ([token.text for token in introduction_doc])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['To', 'jest', 'tutorial', 'petwarzania', 'naturalnych', 'języków', 'w', 'Spacy', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abNcHVp0LDsg",
        "outputId": "71aed820-893c-4a8a-9093-9c9789b3332b"
      },
      "source": [
        "# Czytanie z pliku\n",
        "\n",
        "file_name = 'introduction.txt'\n",
        "introduction_file_text = open(file_name).read()\n",
        "introduction_file_doc = nlp(introduction_file_text)\n",
        "# Extract tokens for the given doc\n",
        "print ([token.text for token in introduction_file_doc])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['To', 'jest', 'tutorial', 'petwarzania', 'naturalnych', 'języków', 'w', 'Spacy', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb7fJrJxQTU3",
        "outputId": "b6de733a-f59a-4825-88a7-41fad3704900"
      },
      "source": [
        "# Wykrywanie zdań ze stringa\n",
        "\n",
        "about_text = ('Maciej Lehmann jest studentem 4 roku'\n",
        "               ' informatyki na Akademii Marynarki'\n",
        "               ' Wojennej w Gdyni. Jest zainteresowany nauką'\n",
        "               ' przetwarzania języka naturalnego. Czerwono-niebieski.')\n",
        "about_doc = nlp(about_text)\n",
        "sentences = list(about_doc.sents)\n",
        "len(sentences)\n",
        "\n",
        "for sentence in sentences:\n",
        "  print (sentence)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej Lehmann jest studentem 4 roku informatyki na Akademii Marynarki Wojennej w Gdyni.\n",
            "Jest zainteresowany nauką przetwarzania języka naturalnego.\n",
            "Czerwono-niebieski.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j58-pcjFVsSy",
        "outputId": "c267c683-2c77-4bb9-cbf6-33d9b59541ae"
      },
      "source": [
        "# Wykrywanie zdań z zastosowaniem własnego separatora\n",
        "\n",
        "def set_custom_boundaries(doc):\n",
        "  for token in doc[:-1]:\n",
        "    if token.text == '...':\n",
        "     doc[token.i+1].is_sent_start = True\n",
        "  return doc\n",
        "\n",
        "ellipsis_text = ('Gus, can you, ... never mind, I forgot'\n",
        "                  ' what I was saying. So, do you think'\n",
        "                  ' we should ...')\n",
        "\n",
        "print(\"Zdania podzielone przy użyciu nowego separatora: \")\n",
        "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
        "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
        "for sentence in custom_ellipsis_sentences:\n",
        "  print(sentence)\n",
        "\n",
        "print(\"\\nZdania z użyciem domyślnego separatora:\")\n",
        "ellipsis_doc = nlp(ellipsis_text)\n",
        "ellipsis_sentences = list(ellipsis_doc.sents)\n",
        "for sentence in ellipsis_sentences:\n",
        "  print(sentence)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zdania podzielone przy użyciu nowego separatora: \n",
            "Gus, can you, ...\n",
            "never mind, I forgot what I was saying.\n",
            "So, do you think we should ...\n",
            "\n",
            "Zdania z użyciem domyślnego separatora:\n",
            "Gus, can you, ... never mind, I forgot what I was saying.\n",
            "So, do you think we should ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BvuBpe4io0-",
        "outputId": "34faeecf-1f11-4758-96c0-33ea8add20c2"
      },
      "source": [
        "# Podział na podstawowe jednostki w tekście - tokeny\n",
        "\n",
        "for token in about_doc:\n",
        "  print (token, token.idx)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej 0\n",
            "Lehmann 7\n",
            "jest 15\n",
            "studentem 20\n",
            "4 30\n",
            "roku 32\n",
            "informatyki 37\n",
            "na 49\n",
            "Akademii 52\n",
            "Marynarki 61\n",
            "Wojennej 71\n",
            "w 80\n",
            "Gdyni 82\n",
            ". 87\n",
            "Jest 89\n",
            "zainteresowany 94\n",
            "nauką 109\n",
            "przetwarzania 115\n",
            "języka 129\n",
            "naturalnego 136\n",
            ". 147\n",
            "Czerwono 149\n",
            "- 157\n",
            "niebieski 158\n",
            ". 167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW7BxzH2mg6e",
        "outputId": "ccc709b8-aae8-4517-9fa3-2c85aacab6d1"
      },
      "source": [
        "# Wskazanie szczegółowych atrybutów tokenów\n",
        "\n",
        "for token in about_doc:\n",
        "  print (token, token.idx, token.text_with_ws, token.is_alpha, token.is_punct, token.is_space, token.shape_, token.is_stop)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej 0 Maciej  True False False Xxxxx False\n",
            "Lehmann 7 Lehmann  True False False Xxxxx False\n",
            "jest 15 jest  True False False xxxx False\n",
            "studentem 20 studentem  True False False xxxx False\n",
            "4 30 4  False False False d False\n",
            "roku 32 roku  True False False xxxx False\n",
            "informatyki 37 informatyki  True False False xxxx False\n",
            "na 49 na  True False False xx False\n",
            "Akademii 52 Akademii  True False False Xxxxx False\n",
            "Marynarki 61 Marynarki  True False False Xxxxx False\n",
            "Wojennej 71 Wojennej  True False False Xxxxx False\n",
            "w 80 w  True False False x False\n",
            "Gdyni 82 Gdyni True False False Xxxxx False\n",
            ". 87 .  False True False . False\n",
            "Jest 89 Jest  True False False Xxxx False\n",
            "zainteresowany 94 zainteresowany  True False False xxxx False\n",
            "nauką 109 nauką  True False False xxxx False\n",
            "przetwarzania 115 przetwarzania  True False False xxxx False\n",
            "języka 129 języka  True False False xxxx False\n",
            "naturalnego 136 naturalnego True False False xxxx False\n",
            ". 147 .  False True False . False\n",
            "Czerwono 149 Czerwono True False False Xxxxx False\n",
            "- 157 - False True False - False\n",
            "niebieski 158 niebieski True False False xxxx False\n",
            ". 167 . False True False . False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGlWG6JgnDQc",
        "outputId": "10a2a824-2128-4356-cb55-1a3580d37336"
      },
      "source": [
        "# Dostosowanie procesu tokenizacji, aby wykrywał tokeny na niestandardowych znakach\n",
        "\n",
        "custom_nlp = spacy.load('en_core_web_sm')\n",
        "prefix_re = spacy.util.compile_prefix_regex(custom_nlp.Defaults.prefixes)\n",
        "suffix_re = spacy.util.compile_suffix_regex(custom_nlp.Defaults.suffixes)\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "def customize_tokenizer(nlp):\n",
        "  return Tokenizer(nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search, infix_finditer=infix_re.finditer, token_match=None)\n",
        "\n",
        "custom_nlp.tokenizer = customize_tokenizer(custom_nlp)\n",
        "custom_tokenizer_about_doc = custom_nlp(about_text)\n",
        "print([token.text for token in custom_tokenizer_about_doc])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Maciej', 'Lehmann', 'jest', 'studentem', '4', 'roku', 'informatyki', 'na', 'Akademii', 'Marynarki', 'Wojennej', 'w', 'Gdyni', '.', 'Jest', 'zainteresowany', 'nauką', 'przetwarzania', 'języka', 'naturalnego', '.', 'Czerwono', '-', 'niebieski', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6eklAopoxJ2",
        "outputId": "f3bd426d-387c-4128-97ff-7600e5d2bb0d"
      },
      "source": [
        "# Wypisanie kilku słów stopów\n",
        "\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "len(spacy_stopwords)\n",
        "\n",
        "for stop_word in list(spacy_stopwords)[:10]:\n",
        "  print(stop_word)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "whoever\n",
            "myself\n",
            "to\n",
            "neither\n",
            "every\n",
            "themselves\n",
            "fifty\n",
            "last\n",
            "see\n",
            "became\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gemqcFZ0skoX",
        "outputId": "684d7c4d-5a58-49df-f510-3d4a2ce839d2"
      },
      "source": [
        "# Wypisanie tokenów pomijając słowa stopy\n",
        "\n",
        "about_text = ('Gus Proto is a Python developer currently'\n",
        "               ' working for a London-based Fintech'\n",
        "               ' company. He is interested in learning'\n",
        "               ' Natural Language Processing.')\n",
        "about_doc = nlp(about_text)\n",
        "\n",
        "\n",
        "for token in about_doc:\n",
        "  if not token.is_stop:\n",
        "    print (token)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus\n",
            "Proto\n",
            "Python\n",
            "developer\n",
            "currently\n",
            "working\n",
            "London\n",
            "-\n",
            "based\n",
            "Fintech\n",
            "company\n",
            ".\n",
            "interested\n",
            "learning\n",
            "Natural\n",
            "Language\n",
            "Processing\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3YlEf5BuXzP",
        "outputId": "403149f8-e2f5-42eb-e77c-c22f84bb4233"
      },
      "source": [
        "# Tworzenie listy tokenów bez słów stopów\n",
        "\n",
        "about_no_stopword_doc = [token for token in about_doc if not token.is_stop]\n",
        "print (about_no_stopword_doc)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Gus, Proto, Python, developer, currently, working, London, -, based, Fintech, company, ., interested, learning, Natural, Language, Processing, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G13iAD6RzTS-",
        "outputId": "8971acd5-918e-4245-ebf5-dc6e9d4c0e29"
      },
      "source": [
        "# Redukcja odmioych form wyrazów\n",
        "\n",
        "conference_help_text = ('Gus is helping organize a developer'\n",
        "     ' conference on Applications of Natural Language'\n",
        "     ' Processing. He keeps organizing local Python meetups'\n",
        "     ' and several internal talks at his workplace.')\n",
        "conference_help_doc = nlp(conference_help_text)\n",
        "for token in conference_help_doc:\n",
        "  print (token, token.lemma_)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus Gus\n",
            "is be\n",
            "helping help\n",
            "organize organize\n",
            "a a\n",
            "developer developer\n",
            "conference conference\n",
            "on on\n",
            "Applications Applications\n",
            "of of\n",
            "Natural Natural\n",
            "Language Language\n",
            "Processing Processing\n",
            ". .\n",
            "He -PRON-\n",
            "keeps keep\n",
            "organizing organize\n",
            "local local\n",
            "Python Python\n",
            "meetups meetup\n",
            "and and\n",
            "several several\n",
            "internal internal\n",
            "talks talk\n",
            "at at\n",
            "his -PRON-\n",
            "workplace workplace\n",
            ". .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwAJyblz0bM3",
        "outputId": "e79f50c4-0462-471f-8b1b-587946e82f3f"
      },
      "source": [
        "# Sprawdzanie statystyk występowania słów w danym tekście\n",
        "\n",
        "from collections import Counter\n",
        "complete_text = ('Gus Proto is a Python developer currently'\n",
        "     ' working for a London-based Fintech company. He is'\n",
        "     ' interested in learning Natural Language Processing.'\n",
        "     ' There is a developer conference happening on 21 July'\n",
        "     ' 2019 in London. It is titled \"Applications of Natural'\n",
        "     ' Language Processing\". There is a helpline number '\n",
        "     ' available at +1-1234567891. Gus is helping organize it.'\n",
        "     ' He keeps organizing local Python meetups and several'\n",
        "     ' internal talks at his workplace. Gus is also presenting'\n",
        "     ' a talk. The talk will introduce the reader about \"Use'\n",
        "     ' cases of Natural Language Processing in Fintech\".'\n",
        "     ' Apart from his work, he is very passionate about music.'\n",
        "     ' Gus is learning to play the Piano. He has enrolled '\n",
        "     ' himself in the weekend batch of Great Piano Academy.'\n",
        "     ' Great Piano Academy is situated in Mayfair or the City'\n",
        "     ' of London and has world-class piano instructors.')\n",
        "\n",
        "complete_doc = nlp(complete_text)\n",
        "\n",
        "words = [token.text for token in complete_doc if not token.is_stop and not token.is_punct]\n",
        "word_freq = Counter(words)\n",
        "\n",
        "common_words = word_freq.most_common(5)\n",
        "print (common_words)\n",
        "\n",
        "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
        "print (unique_words)\n",
        "\n",
        "words_all = [token.text for token in complete_doc if not token.is_punct]\n",
        "word_freq_all = Counter(words_all)\n",
        "\n",
        "common_words_all = word_freq_all.most_common(5)\n",
        "print (common_words_all)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n",
            "['Proto', 'currently', 'working', 'based', 'company', 'interested', 'conference', 'happening', '21', 'July', '2019', 'titled', 'Applications', 'helpline', 'number', 'available', '+1', '1234567891', 'helping', 'organize', 'keeps', 'organizing', 'local', 'meetups', 'internal', 'talks', 'workplace', 'presenting', 'introduce', 'reader', 'Use', 'cases', 'Apart', 'work', 'passionate', 'music', 'play', 'enrolled', 'weekend', 'batch', 'situated', 'Mayfair', 'City', 'world', 'class', 'piano', 'instructors']\n",
            "[('is', 10), ('a', 5), ('in', 5), ('Gus', 4), ('of', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whP4IhPc2GcC",
        "outputId": "488fcd19-d060-44c3-a419-b45ea85b96f0"
      },
      "source": [
        "# Określenie jaką część mowy stanowią dane słowa\n",
        "\n",
        "for token in about_doc:\n",
        "  print (token, token.tag_, token.pos_, spacy.explain(token.tag_))\n",
        "\n",
        "nouns = []\n",
        "adjectives = []\n",
        "for token in about_doc:\n",
        "  if token.pos_ == 'NOUN':\n",
        "    nouns.append(token)\n",
        "  if token.pos_ == 'ADJ':\n",
        "    adjectives.append(token)\n",
        "\n",
        "print(\"\\n\\nNouns: \", nouns)\n",
        "\n",
        "print(\"Adjectives: \", adjectives)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus NNP PROPN noun, proper singular\n",
            "Proto NNP PROPN noun, proper singular\n",
            "is VBZ AUX verb, 3rd person singular present\n",
            "a DT DET determiner\n",
            "Python NNP PROPN noun, proper singular\n",
            "developer NN NOUN noun, singular or mass\n",
            "currently RB ADV adverb\n",
            "working VBG VERB verb, gerund or present participle\n",
            "for IN ADP conjunction, subordinating or preposition\n",
            "a DT DET determiner\n",
            "London NNP PROPN noun, proper singular\n",
            "- HYPH PUNCT punctuation mark, hyphen\n",
            "based VBN VERB verb, past participle\n",
            "Fintech NNP PROPN noun, proper singular\n",
            "company NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "He PRP PRON pronoun, personal\n",
            "is VBZ AUX verb, 3rd person singular present\n",
            "interested JJ ADJ adjective\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "learning VBG VERB verb, gerund or present participle\n",
            "Natural NNP PROPN noun, proper singular\n",
            "Language NNP PROPN noun, proper singular\n",
            "Processing NNP PROPN noun, proper singular\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "\n",
            "\n",
            "Nouns:  [developer, company]\n",
            "Adjectives:  [interested]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "kR0sQW543jxD",
        "outputId": "5e6f46e4-5922-46a9-f049-e4030d9f7688"
      },
      "source": [
        "about_interest_text = ('He is interested in learning' ' Natural Language Processing.')\n",
        "about_interest_doc = nlp(about_interest_text)\n",
        "displacy.render(about_interest_doc, style='dep', jupyter=True)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ba61bfbe05884ace9f0bb78ebe5195ff-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ba61bfbe05884ace9f0bb78ebe5195ff-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CzRAoNd5Mej",
        "outputId": "d974fb70-9fd9-4ae9-80bc-0e65f46d44e8"
      },
      "source": [
        "# Tworzenie funkcji, która konwertuje tekst do formy, którą można analizować\n",
        "\n",
        "def is_token_allowed(token):\n",
        "  if (not token or not token.string.strip() or\n",
        "    token.is_stop or token.is_punct):\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def preprocess_token(token):\n",
        "  return token.lemma_.strip().lower()\n",
        "\n",
        "complete_filtered_tokens = [preprocess_token(token)\n",
        "for token in complete_doc if is_token_allowed(token)]\n",
        "complete_filtered_tokens"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gus',\n",
              " 'proto',\n",
              " 'python',\n",
              " 'developer',\n",
              " 'currently',\n",
              " 'work',\n",
              " 'london',\n",
              " 'base',\n",
              " 'fintech',\n",
              " 'company',\n",
              " 'interested',\n",
              " 'learn',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'developer',\n",
              " 'conference',\n",
              " 'happen',\n",
              " '21',\n",
              " 'july',\n",
              " '2019',\n",
              " 'london',\n",
              " 'title',\n",
              " 'applications',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'helpline',\n",
              " 'number',\n",
              " 'available',\n",
              " '+1',\n",
              " '1234567891',\n",
              " 'gus',\n",
              " 'help',\n",
              " 'organize',\n",
              " 'keep',\n",
              " 'organize',\n",
              " 'local',\n",
              " 'python',\n",
              " 'meetup',\n",
              " 'internal',\n",
              " 'talk',\n",
              " 'workplace',\n",
              " 'gus',\n",
              " 'present',\n",
              " 'talk',\n",
              " 'talk',\n",
              " 'introduce',\n",
              " 'reader',\n",
              " 'use',\n",
              " 'case',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'fintech',\n",
              " 'apart',\n",
              " 'work',\n",
              " 'passionate',\n",
              " 'music',\n",
              " 'gus',\n",
              " 'learn',\n",
              " 'play',\n",
              " 'piano',\n",
              " 'enrol',\n",
              " 'weekend',\n",
              " 'batch',\n",
              " 'great',\n",
              " 'piano',\n",
              " 'academy',\n",
              " 'great',\n",
              " 'piano',\n",
              " 'academy',\n",
              " 'situate',\n",
              " 'mayfair',\n",
              " 'city',\n",
              " 'london',\n",
              " 'world',\n",
              " 'class',\n",
              " 'piano',\n",
              " 'instructor']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZzQMlCVQ-R8h",
        "outputId": "216cd1d1-9c12-4f44-e57b-6f0c276c42e0"
      },
      "source": [
        "# Wyciąganie imienia i nazwiska za pomocą dopasowania opartego o wskazane reguły\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "def extract_full_name(nlp_doc):\n",
        "  pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "  matcher.add('FULL_NAME', None, pattern)\n",
        "  matches = matcher(nlp_doc)\n",
        "  for match_id, start, end in matches:\n",
        "    span = nlp_doc[start:end]\n",
        "    return span.text\n",
        "\n",
        "extract_full_name(about_doc)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Gus Proto'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sxZvi_5e_gLD",
        "outputId": "9cd74abb-379f-4bd4-d95e-a8c293e52b3c"
      },
      "source": [
        "# Użycie dopasowania opartego na regułach do wyciągnięcia numeru telefonu\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "conference_org_text = ('There is a developer conference'\n",
        "     'happening on 21 July 2019 in London. It is titled'\n",
        "     ' \"Applications of Natural Language Processing\".'\n",
        "     ' There is a helpline number available'\n",
        "     ' at (123) 456-789')\n",
        "\n",
        "def extract_phone_number(nlp_doc):\n",
        "  pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
        "                {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
        "                {'ORTH': '-', 'OP': '?'},\n",
        "                {'SHAPE': 'ddd'}]\n",
        "  matcher.add('PHONE_NUMBER', None, pattern)\n",
        "  matches = matcher(nlp_doc)\n",
        "  for match_id, start, end in matches:\n",
        "    span = nlp_doc[start:end]\n",
        "    return span.text\n",
        "\n",
        "conference_org_doc = nlp(conference_org_text)\n",
        "extract_phone_number(conference_org_doc)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(123) 456-789'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "DfoUNQ6p_9w8",
        "outputId": "c83e9c22-2545-4137-bdaf-422ebc0b78e5"
      },
      "source": [
        "piano_text = 'Gus is learning piano'\n",
        "piano_doc = nlp(piano_text)\n",
        "for token in piano_doc:\n",
        "  print (token.text, token.tag_, token.head.text, token.dep_)\n",
        "\n",
        "displacy.render(piano_doc, style='dep', jupyter=True)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus NNP learning nsubj\n",
            "is VBZ learning aux\n",
            "learning VBG learning ROOT\n",
            "piano NN learning dobj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"474e719d8e7b4dea971cb308e2f07915-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Gus</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">piano</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-474e719d8e7b4dea971cb308e2f07915-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-474e719d8e7b4dea971cb308e2f07915-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-474e719d8e7b4dea971cb308e2f07915-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-474e719d8e7b4dea971cb308e2f07915-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-474e719d8e7b4dea971cb308e2f07915-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-474e719d8e7b4dea971cb308e2f07915-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgNmDwuQBGUi",
        "outputId": "86a89de6-2bc4-4fce-f58f-3e57b7ade16d"
      },
      "source": [
        "# Drzewo posiada informacje o strukturze zdań i gramatyce i można je przeglądać na różne sposoby, aby wyodrębnić relacje\n",
        "\n",
        "one_line_about_text = ('Gus Proto is a Python developer'\n",
        "' currently working for a London-based Fintech company')\n",
        "one_line_about_doc = nlp(one_line_about_text)\n",
        "# Extract children of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].children])\n",
        "\n",
        "# Extract previous neighboring node of `developer`\n",
        "print (one_line_about_doc[5].nbor(-1))\n",
        "\n",
        "# Extract next neighboring node of `developer`\n",
        "print (one_line_about_doc[5].nbor())\n",
        "\n",
        "# Extract all tokens on the left of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].lefts])\n",
        "\n",
        "# Extract tokens on the right of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].rights])\n",
        "\n",
        "# Print subtree of `developer`\n",
        "print (list(one_line_about_doc[5].subtree))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'Python', 'working']\n",
            "Python\n",
            "currently\n",
            "['a', 'Python']\n",
            "['working']\n",
            "[a, Python, developer, currently, working, for, a, London, -, based, Fintech, company]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NA8junQB-_X",
        "outputId": "25df941b-f138-422c-ade8-c0ea6f3686e7"
      },
      "source": [
        "# Tworzenie funkcji, która tworzy stringa na podstawie drzewa\n",
        "\n",
        "def flatten_tree(tree):\n",
        "  return ''.join([token.text_with_ws for token in list(tree)]).strip()\n",
        "\n",
        "# Print flattened subtree of `developer`\n",
        "print (flatten_tree(one_line_about_doc[5].subtree))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a Python developer currently working for a London-based Fintech company\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND6rn_ROCF3a",
        "outputId": "53db6a66-a7e4-4eea-9160-3b88a4663ff7"
      },
      "source": [
        "# Wykrywanie fraz rzeczownikowych w tekście\n",
        "\n",
        "conference_text = ('There is a developer conference' ' happening on 21 July 2019 in London.')\n",
        "conference_doc = nlp(conference_text)\n",
        "# Extract Noun Phrases\n",
        "for chunk in conference_doc.noun_chunks:\n",
        "  print (chunk)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a developer conference\n",
            "21 July\n",
            "London\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bJsjg0OCQrg",
        "outputId": "0cb43697-dac9-4c20-f85e-65263bfae596"
      },
      "source": [
        "# Wykrywanie fraz czaskownikowych w tekście\n",
        "\n",
        "about_talk_text = ('The talk will introduce reader about Use'\n",
        "                    ' cases of Natural Language Processing in'\n",
        "                    ' Fintech')\n",
        "pattern = r'(<VERB>?<ADV>*<VERB>+)'\n",
        "about_talk_doc = textacy.make_spacy_doc(about_talk_text, lang='en_core_web_sm')\n",
        "verb_phrases = textacy.extract.pos_regex_matches(about_talk_doc, pattern)\n",
        "# Print all Verb Phrase\n",
        "for chunk in verb_phrases:\n",
        "  print(chunk.text)\n",
        "\n",
        "# Extract Noun Phrase to explain what nouns are involved\n",
        "for chunk in about_talk_doc.noun_chunks:\n",
        "  print (chunk)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "will introduce\n",
            "The talk\n",
            "reader\n",
            "Use cases\n",
            "Natural Language Processing\n",
            "Fintech\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/textacy/extract.py:338: DeprecationWarning: `pos_regex_matches()` has been deprecated! for similar but more powerful and performant functionality, use `textacy.extract.matches()` instead.\n",
            "  action=\"once\",\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "7weTCwg8C2qj",
        "outputId": "78b7f547-20a4-4a96-ada9-2f212b722a23"
      },
      "source": [
        "# Znajdowanie nazwanych obiektów w tekście\n",
        "\n",
        "piano_class_text = ('Great Piano Academy is situated'\n",
        "     ' in Mayfair or the City of London and has'\n",
        "     ' world-class piano instructors.')\n",
        "piano_class_doc = nlp(piano_class_text)\n",
        "for ent in piano_class_doc.ents:\n",
        "  print(ent.text, ent.start_char, ent.end_char, ent.label_, spacy.explain(ent.label_))\n",
        "\n",
        "displacy.render(piano_class_doc, style='ent', jupyter=True)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Great Piano Academy 0 19 ORG Companies, agencies, institutions, etc.\n",
            "Mayfair 35 42 GPE Countries, cities, states\n",
            "the City of London 46 64 GPE Countries, cities, states\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Great Piano Academy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is situated in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mayfair\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " or \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the City of London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and has world-class piano instructors.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nCmCW56nDU22",
        "outputId": "f0cb4e01-9c61-47aa-e1f0-0e58877d26e9"
      },
      "source": [
        "# Ukrywanie imion w tekście w oparciu o nazwane obiekty\n",
        "\n",
        "survey_text = ('Out of 5 people surveyed, James Robert,'\n",
        "                ' Julie Fuller and Benjamin Brooks like'\n",
        "                ' apples. Kelly Cox and Matthew Evans'\n",
        "                ' like oranges.')\n",
        "\n",
        "def replace_person_names(token):\n",
        "  if token.ent_iob != 0 and token.ent_type_ == 'PERSON':\n",
        "    return '[CONFIDENTIAL] '\n",
        "  return token.string\n",
        "\n",
        "def redact_names(nlp_doc):\n",
        "  for ent in nlp_doc.ents:\n",
        "    ent.merge()\n",
        "  tokens = map(replace_person_names, nlp_doc)\n",
        "  return ''.join(tokens)\n",
        "\n",
        "survey_doc = nlp(survey_text)\n",
        "redact_names(survey_doc)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Out of 5 people surveyed, [CONFIDENTIAL] , [CONFIDENTIAL] and [CONFIDENTIAL] like apples. [CONFIDENTIAL] and [CONFIDENTIAL] like oranges.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    }
  ]
}