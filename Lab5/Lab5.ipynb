{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpYoieG8PAlWOVmEndHTH7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maciejlehmann/amw-wdum/blob/main/Lab5/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVVVQz6PJuRi"
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "import textacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXDUJvyIKFBz",
        "outputId": "03617426-4bcd-448a-da4d-65a6a54c8c8a"
      },
      "source": [
        "# Czytanie ze stringa\n",
        "\n",
        "introduction_text = ('This is just an example sentence for a task.')\n",
        "introduction_doc = nlp(introduction_text)\n",
        "\n",
        "print ([token.text for token in introduction_doc])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'just', 'an', 'example', 'sentence', 'for', 'a', 'task', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abNcHVp0LDsg",
        "outputId": "6144c7bc-4aa2-4de1-f025-1b2379a8fcd3"
      },
      "source": [
        "# Czytanie z pliku\n",
        "\n",
        "file_name = 'introduction.txt'\n",
        "introduction_file_text = open(file_name).read()\n",
        "introduction_file_doc = nlp(introduction_file_text)\n",
        "\n",
        "print ([token.text for token in introduction_file_doc])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My', 'name', 'is', 'Maciej', '.', 'I', 'am', 'studying', 'computer', 'science', 'at', 'the', 'Naval', 'Academy', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb7fJrJxQTU3",
        "outputId": "2b7d912a-b876-4082-c094-028bb82d9732"
      },
      "source": [
        "# Wykrywanie zdań ze stringa\n",
        "\n",
        "about_text = ('Maciej Lehmann is a 4th year'\n",
        "               ' computer science student at the Naval'\n",
        "               ' Academy in Gdynia. He is in the process'\n",
        "               ' of preparing his engineering thesis.')\n",
        "about_doc = nlp(about_text)\n",
        "sentences = list(about_doc.sents)\n",
        "len(sentences)\n",
        "\n",
        "for sentence in sentences:\n",
        "  print (sentence)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej Lehmann is a 4th year computer science student at the Naval Academy in Gdynia.\n",
            "He is in the process of preparing his engineering thesis.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j58-pcjFVsSy",
        "outputId": "248a2938-49c6-4e6b-bc4b-c362653d35ee"
      },
      "source": [
        "# Wykrywanie zdań z zastosowaniem własnego separatora\n",
        "\n",
        "def set_custom_boundaries(doc):\n",
        "  for token in doc[:-1]:\n",
        "    if token.text == '...':\n",
        "     doc[token.i+1].is_sent_start = True\n",
        "  return doc\n",
        "\n",
        "ellipsis_text = ('Maciej Lehmann is ... a 4th year'\n",
        "               ' computer science student at the Naval'\n",
        "               ' Academy ... in Gdynia. He is in the process'\n",
        "               ' of preparing ... his engineering thesis.')\n",
        "\n",
        "print(\"Zdania podzielone przy użyciu nowego separatora: \")\n",
        "custom_nlp = spacy.load('en_core_web_sm')\n",
        "custom_nlp.add_pipe(set_custom_boundaries, before='parser')\n",
        "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
        "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
        "for sentence in custom_ellipsis_sentences:\n",
        "  print(sentence)\n",
        "\n",
        "print(\"\\nZdania z użyciem domyślnego separatora:\")\n",
        "ellipsis_doc = nlp(ellipsis_text)\n",
        "ellipsis_sentences = list(ellipsis_doc.sents)\n",
        "for sentence in ellipsis_sentences:\n",
        "  print(sentence)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zdania podzielone przy użyciu nowego separatora: \n",
            "Maciej Lehmann is ...\n",
            "a 4th year computer science student at the Naval Academy ...\n",
            "in Gdynia.\n",
            "He is in the process of preparing ...\n",
            "his engineering thesis.\n",
            "\n",
            "Zdania z użyciem domyślnego separatora:\n",
            "Maciej Lehmann is ... a 4th year computer science student at the Naval Academy ... in Gdynia.\n",
            "He is in the process of preparing ...\n",
            "his engineering thesis.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BvuBpe4io0-",
        "outputId": "75118978-8248-4b69-a33f-35c0f4d8f714"
      },
      "source": [
        "# Podział na podstawowe jednostki w tekście - tokeny\n",
        "\n",
        "for token in about_doc:\n",
        "  print (token, token.idx)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej 0\n",
            "Lehmann 7\n",
            "is 15\n",
            "a 18\n",
            "4th 20\n",
            "year 24\n",
            "computer 29\n",
            "science 38\n",
            "student 46\n",
            "at 54\n",
            "the 57\n",
            "Naval 61\n",
            "Academy 67\n",
            "in 75\n",
            "Gdynia 78\n",
            ". 84\n",
            "He 86\n",
            "is 89\n",
            "in 92\n",
            "the 95\n",
            "process 99\n",
            "of 107\n",
            "preparing 110\n",
            "his 120\n",
            "engineering 124\n",
            "thesis 136\n",
            ". 142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW7BxzH2mg6e",
        "outputId": "26f13a80-54e6-47a4-c1af-64ae5cbf1c3a"
      },
      "source": [
        "# Wskazanie szczegółowych atrybutów tokenów\n",
        "\n",
        "for token in about_doc:\n",
        "  print (token, token.idx, token.text_with_ws, token.is_alpha, token.is_punct, token.is_space, token.shape_, token.is_stop)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej 0 Maciej  True False False Xxxxx False\n",
            "Lehmann 7 Lehmann  True False False Xxxxx False\n",
            "is 15 is  True False False xx True\n",
            "a 18 a  True False False x True\n",
            "4th 20 4th  False False False dxx False\n",
            "year 24 year  True False False xxxx False\n",
            "computer 29 computer  True False False xxxx False\n",
            "science 38 science  True False False xxxx False\n",
            "student 46 student  True False False xxxx False\n",
            "at 54 at  True False False xx True\n",
            "the 57 the  True False False xxx True\n",
            "Naval 61 Naval  True False False Xxxxx False\n",
            "Academy 67 Academy  True False False Xxxxx False\n",
            "in 75 in  True False False xx True\n",
            "Gdynia 78 Gdynia True False False Xxxxx False\n",
            ". 84 .  False True False . False\n",
            "He 86 He  True False False Xx True\n",
            "is 89 is  True False False xx True\n",
            "in 92 in  True False False xx True\n",
            "the 95 the  True False False xxx True\n",
            "process 99 process  True False False xxxx False\n",
            "of 107 of  True False False xx True\n",
            "preparing 110 preparing  True False False xxxx False\n",
            "his 120 his  True False False xxx True\n",
            "engineering 124 engineering  True False False xxxx False\n",
            "thesis 136 thesis True False False xxxx False\n",
            ". 142 . False True False . False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGlWG6JgnDQc",
        "outputId": "59945c95-b131-44f1-e32b-918fd19f8f57"
      },
      "source": [
        "# Dostosowanie procesu tokenizacji, aby wykrywał tokeny na niestandardowych znakach\n",
        "\n",
        "custom_nlp = spacy.load('en_core_web_sm')\n",
        "prefix_re = spacy.util.compile_prefix_regex(custom_nlp.Defaults.prefixes)\n",
        "suffix_re = spacy.util.compile_suffix_regex(custom_nlp.Defaults.suffixes)\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "def customize_tokenizer(nlp):\n",
        "  return Tokenizer(nlp.vocab, prefix_search=prefix_re.search, suffix_search=suffix_re.search, infix_finditer=infix_re.finditer, token_match=None)\n",
        "\n",
        "custom_nlp.tokenizer = customize_tokenizer(custom_nlp)\n",
        "custom_tokenizer_about_doc = custom_nlp(about_text)\n",
        "print([token.text for token in custom_tokenizer_about_doc])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Maciej', 'Lehmann', 'is', 'a', '4th', 'year', 'computer', 'science', 'student', 'at', 'the', 'Naval', 'Academy', 'in', 'Gdynia', '.', 'He', 'is', 'in', 'the', 'process', 'of', 'preparing', 'his', 'engineering', 'thesis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6eklAopoxJ2",
        "outputId": "b5e6da87-c73b-41ef-eed4-c27b686f03b7"
      },
      "source": [
        "# Wypisanie kilku słów stopów\n",
        "\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "len(spacy_stopwords)\n",
        "\n",
        "for stop_word in list(spacy_stopwords)[:10]:\n",
        "  print(stop_word)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yet\n",
            "thereupon\n",
            "they\n",
            "are\n",
            "up\n",
            "why\n",
            "'m\n",
            "mostly\n",
            "regarding\n",
            "almost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gemqcFZ0skoX",
        "outputId": "a4c740a9-1cdd-41df-c3df-806a87e4708d"
      },
      "source": [
        "# Wypisanie tokenów pomijając słowa stopy\n",
        "\n",
        "about_text = ('Maciej Lehmann is a 4th year'\n",
        "               ' computer science student at the Naval'\n",
        "               ' Academy in Gdynia. He is in the process'\n",
        "               ' of preparing his engineering thesis.')\n",
        "about_doc = nlp(about_text)\n",
        "\n",
        "\n",
        "for token in about_doc:\n",
        "  if not token.is_stop:\n",
        "    print (token)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej\n",
            "Lehmann\n",
            "4th\n",
            "year\n",
            "computer\n",
            "science\n",
            "student\n",
            "Naval\n",
            "Academy\n",
            "Gdynia\n",
            ".\n",
            "process\n",
            "preparing\n",
            "engineering\n",
            "thesis\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3YlEf5BuXzP",
        "outputId": "63d09df2-0d78-402b-bba2-e2c808417750"
      },
      "source": [
        "# Tworzenie listy tokenów bez słów stopów\n",
        "\n",
        "about_no_stopword_doc = [token for token in about_doc if not token.is_stop]\n",
        "print (about_no_stopword_doc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Maciej, Lehmann, 4th, year, computer, science, student, Naval, Academy, Gdynia, ., process, preparing, engineering, thesis, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G13iAD6RzTS-",
        "outputId": "888d528e-acab-42e2-df16-fc1fab7f95db"
      },
      "source": [
        "# Redukcja odmioych form wyrazów\n",
        "\n",
        "conference_help_text = ('Maciej Lehmann is a 4th year'\n",
        "               ' computer science student at the Naval'\n",
        "               ' Academy in Gdynia. He is in the process'\n",
        "               ' of preparing his engineering thesis.')\n",
        "conference_help_doc = nlp(conference_help_text)\n",
        "for token in conference_help_doc:\n",
        "  print (token, token.lemma_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej Maciej\n",
            "Lehmann Lehmann\n",
            "is be\n",
            "a a\n",
            "4th 4th\n",
            "year year\n",
            "computer computer\n",
            "science science\n",
            "student student\n",
            "at at\n",
            "the the\n",
            "Naval Naval\n",
            "Academy Academy\n",
            "in in\n",
            "Gdynia Gdynia\n",
            ". .\n",
            "He -PRON-\n",
            "is be\n",
            "in in\n",
            "the the\n",
            "process process\n",
            "of of\n",
            "preparing prepare\n",
            "his -PRON-\n",
            "engineering engineering\n",
            "thesis thesis\n",
            ". .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwAJyblz0bM3",
        "outputId": "05006fb9-436c-46d8-cf87-b8e7835653e0"
      },
      "source": [
        "# Sprawdzanie statystyk występowania słów w danym tekście\n",
        "\n",
        "from collections import Counter\n",
        "complete_text = ('Avengers: Endgame is the culmination of a decade of blockbuster'\n",
        "     ' filmmaking, the result of years of work from thousands of people. It is'\n",
        "     ' designed to be the most blockbuster of all the blockbusters, a movie'\n",
        "     ' with a dozen subplots colliding, and familiar faces from over 20 other'\n",
        "     ' movies. It’s really like nothing that Hollywood has produced before,'\n",
        "     ' existing not just to acknowledge or exploit the fans of this series, but to'\n",
        "     ' reward their love, patience, and undying adoration. The blunt thing'\n",
        "     ' you probably want to know most: It’s hard to see serious MCU fans'\n",
        "     ' walking away from this disappointed. It checks all the boxes, even'\n",
        "     ' ticking off a few ones that fans won’t expect to be on the list. It’s a'\n",
        "     ' satisfying end to a chapter of blockbuster history that will be hard to'\n",
        "     ' top for pure spectacle. In terms of sheer entertainment value, it’s on'\n",
        "     ' the higher end of the MCU, a film that elevates its most iconic heroes'\n",
        "     ' to the legendary status they deserve and provides a few legitimate'\n",
        "     ' thrills along the way.')\n",
        "\n",
        "complete_doc = nlp(complete_text)\n",
        "\n",
        "words = [token.text for token in complete_doc if not token.is_stop and not token.is_punct]\n",
        "word_freq = Counter(words)\n",
        "\n",
        "common_words = word_freq.most_common(5)\n",
        "print (common_words)\n",
        "\n",
        "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
        "print (unique_words)\n",
        "\n",
        "words_all = [token.text for token in complete_doc if not token.is_punct]\n",
        "word_freq_all = Counter(words_all)\n",
        "\n",
        "common_words_all = word_freq_all.most_common(5)\n",
        "print (common_words_all)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('blockbuster', 3), ('fans', 3), ('hard', 2), ('MCU', 2), ('end', 2)]\n",
            "['Avengers', 'Endgame', 'culmination', 'decade', 'filmmaking', 'result', 'years', 'work', 'thousands', 'people', 'designed', 'blockbusters', 'movie', 'dozen', 'subplots', 'colliding', 'familiar', 'faces', '20', 'movies', 'like', 'Hollywood', 'produced', 'existing', 'acknowledge', 'exploit', 'series', 'reward', 'love', 'patience', 'undying', 'adoration', 'blunt', 'thing', 'probably', 'want', 'know', 'walking', 'away', 'disappointed', 'checks', 'boxes', 'ticking', 'ones', 'wo', 'expect', 'list', 'satisfying', 'chapter', 'history', 'pure', 'spectacle', 'terms', 'sheer', 'entertainment', 'value', 'higher', 'film', 'elevates', 'iconic', 'heroes', 'legendary', 'status', 'deserve', 'provides', 'legitimate', 'thrills', 'way']\n",
            "[('the', 11), ('of', 10), ('to', 9), ('a', 8), ('It', 5)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whP4IhPc2GcC",
        "outputId": "e6394b43-060e-433a-bcc7-0a8b8c8e8cde"
      },
      "source": [
        "# Określenie jaką część mowy stanowią dane słowa\n",
        "\n",
        "for token in about_doc:\n",
        "  print (token, token.tag_, token.pos_, spacy.explain(token.tag_))\n",
        "\n",
        "nouns = []\n",
        "adjectives = []\n",
        "for token in about_doc:\n",
        "  if token.pos_ == 'NOUN':\n",
        "    nouns.append(token)\n",
        "  if token.pos_ == 'ADJ':\n",
        "    adjectives.append(token)\n",
        "\n",
        "print(\"\\n\\nNouns: \", nouns)\n",
        "\n",
        "print(\"Adjectives: \", adjectives)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej NNP PROPN noun, proper singular\n",
            "Lehmann NNP PROPN noun, proper singular\n",
            "is VBZ AUX verb, 3rd person singular present\n",
            "a DT DET determiner\n",
            "4th JJ ADJ adjective\n",
            "year NN NOUN noun, singular or mass\n",
            "computer NN NOUN noun, singular or mass\n",
            "science NN NOUN noun, singular or mass\n",
            "student NN NOUN noun, singular or mass\n",
            "at IN ADP conjunction, subordinating or preposition\n",
            "the DT DET determiner\n",
            "Naval NNP PROPN noun, proper singular\n",
            "Academy NNP PROPN noun, proper singular\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "Gdynia NNP PROPN noun, proper singular\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "He PRP PRON pronoun, personal\n",
            "is VBZ AUX verb, 3rd person singular present\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "the DT DET determiner\n",
            "process NN NOUN noun, singular or mass\n",
            "of IN ADP conjunction, subordinating or preposition\n",
            "preparing VBG VERB verb, gerund or present participle\n",
            "his PRP$ DET pronoun, possessive\n",
            "engineering NN NOUN noun, singular or mass\n",
            "thesis NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "\n",
            "\n",
            "Nouns:  [year, computer, science, student, process, engineering, thesis]\n",
            "Adjectives:  [4th]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "kR0sQW543jxD",
        "outputId": "c80752b9-1447-401a-e433-a2ded4bdeded"
      },
      "source": [
        "about_interest_text = ('He is interested in learning' ' Vue.js frontend framework.')\n",
        "about_interest_doc = nlp(about_interest_text)\n",
        "displacy.render(about_interest_doc, style='dep', jupyter=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ca56ca73a21847dba29e6f6f0d2e0e4f-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Vue.js</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">frontend</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">framework.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ca56ca73a21847dba29e6f6f0d2e0e4f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CzRAoNd5Mej",
        "outputId": "139f2951-c5f0-4c17-fc65-c3ec74b821bc"
      },
      "source": [
        "# Tworzenie funkcji, która konwertuje tekst do formy, którą można analizować\n",
        "\n",
        "def is_token_allowed(token):\n",
        "  if (not token or not token.string.strip() or\n",
        "    token.is_stop or token.is_punct):\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def preprocess_token(token):\n",
        "  return token.lemma_.strip().lower()\n",
        "\n",
        "complete_filtered_tokens = [preprocess_token(token)\n",
        "for token in complete_doc if is_token_allowed(token)]\n",
        "complete_filtered_tokens"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['avenger',\n",
              " 'endgame',\n",
              " 'culmination',\n",
              " 'decade',\n",
              " 'blockbuster',\n",
              " 'filmmaking',\n",
              " 'result',\n",
              " 'year',\n",
              " 'work',\n",
              " 'thousand',\n",
              " 'people',\n",
              " 'design',\n",
              " 'blockbuster',\n",
              " 'blockbuster',\n",
              " 'movie',\n",
              " 'dozen',\n",
              " 'subplot',\n",
              " 'colliding',\n",
              " 'familiar',\n",
              " 'face',\n",
              " '20',\n",
              " 'movie',\n",
              " 'like',\n",
              " 'hollywood',\n",
              " 'produce',\n",
              " 'exist',\n",
              " 'acknowledge',\n",
              " 'exploit',\n",
              " 'fan',\n",
              " 'series',\n",
              " 'reward',\n",
              " 'love',\n",
              " 'patience',\n",
              " 'undying',\n",
              " 'adoration',\n",
              " 'blunt',\n",
              " 'thing',\n",
              " 'probably',\n",
              " 'want',\n",
              " 'know',\n",
              " 'hard',\n",
              " 'mcu',\n",
              " 'fan',\n",
              " 'walk',\n",
              " 'away',\n",
              " 'disappointed',\n",
              " 'check',\n",
              " 'box',\n",
              " 'tick',\n",
              " 'one',\n",
              " 'fan',\n",
              " 'will',\n",
              " 'expect',\n",
              " 'list',\n",
              " 'satisfying',\n",
              " 'end',\n",
              " 'chapter',\n",
              " 'blockbuster',\n",
              " 'history',\n",
              " 'hard',\n",
              " 'pure',\n",
              " 'spectacle',\n",
              " 'term',\n",
              " 'sheer',\n",
              " 'entertainment',\n",
              " 'value',\n",
              " 'high',\n",
              " 'end',\n",
              " 'mcu',\n",
              " 'film',\n",
              " 'elevate',\n",
              " 'iconic',\n",
              " 'hero',\n",
              " 'legendary',\n",
              " 'status',\n",
              " 'deserve',\n",
              " 'provide',\n",
              " 'legitimate',\n",
              " 'thrill',\n",
              " 'way']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZzQMlCVQ-R8h",
        "outputId": "fb754485-17be-4ade-c7dd-b0cd0c6182cf"
      },
      "source": [
        "# Wyciąganie imienia i nazwiska za pomocą dopasowania opartego o wskazane reguły\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "def extract_full_name(nlp_doc):\n",
        "  pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "  matcher.add('FULL_NAME', None, pattern)\n",
        "  matches = matcher(nlp_doc)\n",
        "  for match_id, start, end in matches:\n",
        "    span = nlp_doc[start:end]\n",
        "    return span.text\n",
        "\n",
        "extract_full_name(about_doc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Maciej Lehmann'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sxZvi_5e_gLD",
        "outputId": "3cf8d277-1d79-432e-d77f-de432469b986"
      },
      "source": [
        "# Użycie dopasowania opartego na regułach do wyciągnięcia numeru telefonu\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "conference_org_text = ('There is a developer conference'\n",
        "     'happening on 21 July 2019 in London. It is titled'\n",
        "     ' \"Applications of Natural Language Processing\".'\n",
        "     ' There is a helpline number available'\n",
        "     ' at (123) 456-789')\n",
        "\n",
        "def extract_phone_number(nlp_doc):\n",
        "  pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
        "                {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
        "                {'ORTH': '-', 'OP': '?'},\n",
        "                {'SHAPE': 'ddd'}]\n",
        "  matcher.add('PHONE_NUMBER', None, pattern)\n",
        "  matches = matcher(nlp_doc)\n",
        "  for match_id, start, end in matches:\n",
        "    span = nlp_doc[start:end]\n",
        "    return span.text\n",
        "\n",
        "conference_org_doc = nlp(conference_org_text)\n",
        "extract_phone_number(conference_org_doc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(123) 456-789'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "DfoUNQ6p_9w8",
        "outputId": "506f4978-d020-45ff-841c-b1f641749d6c"
      },
      "source": [
        "piano_text = 'Maciej is watching movies'\n",
        "piano_doc = nlp(piano_text)\n",
        "for token in piano_doc:\n",
        "  print (token.text, token.tag_, token.head.text, token.dep_)\n",
        "\n",
        "displacy.render(piano_doc, style='dep', jupyter=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maciej NNP watching nsubj\n",
            "is VBZ watching aux\n",
            "watching VBG watching ROOT\n",
            "movies NNS watching dobj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e33406f0710944158f9b1ec0d30371a0-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Maciej</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">watching</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">movies</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e33406f0710944158f9b1ec0d30371a0-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e33406f0710944158f9b1ec0d30371a0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e33406f0710944158f9b1ec0d30371a0-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e33406f0710944158f9b1ec0d30371a0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e33406f0710944158f9b1ec0d30371a0-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e33406f0710944158f9b1ec0d30371a0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgNmDwuQBGUi",
        "outputId": "86a89de6-2bc4-4fce-f58f-3e57b7ade16d"
      },
      "source": [
        "# Drzewo posiada informacje o strukturze zdań i gramatyce i można je przeglądać na różne sposoby, aby wyodrębnić relacje\n",
        "\n",
        "one_line_about_text = ('Gus Proto is a Python developer'\n",
        "' currently working for a London-based Fintech company')\n",
        "one_line_about_doc = nlp(one_line_about_text)\n",
        "# Extract children of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].children])\n",
        "\n",
        "# Extract previous neighboring node of `developer`\n",
        "print (one_line_about_doc[5].nbor(-1))\n",
        "\n",
        "# Extract next neighboring node of `developer`\n",
        "print (one_line_about_doc[5].nbor())\n",
        "\n",
        "# Extract all tokens on the left of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].lefts])\n",
        "\n",
        "# Extract tokens on the right of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].rights])\n",
        "\n",
        "# Print subtree of `developer`\n",
        "print (list(one_line_about_doc[5].subtree))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'Python', 'working']\n",
            "Python\n",
            "currently\n",
            "['a', 'Python']\n",
            "['working']\n",
            "[a, Python, developer, currently, working, for, a, London, -, based, Fintech, company]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NA8junQB-_X",
        "outputId": "25df941b-f138-422c-ade8-c0ea6f3686e7"
      },
      "source": [
        "# Tworzenie funkcji, która tworzy stringa na podstawie drzewa\n",
        "\n",
        "def flatten_tree(tree):\n",
        "  return ''.join([token.text_with_ws for token in list(tree)]).strip()\n",
        "\n",
        "# Print flattened subtree of `developer`\n",
        "print (flatten_tree(one_line_about_doc[5].subtree))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a Python developer currently working for a London-based Fintech company\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND6rn_ROCF3a",
        "outputId": "53db6a66-a7e4-4eea-9160-3b88a4663ff7"
      },
      "source": [
        "# Wykrywanie fraz rzeczownikowych w tekście\n",
        "\n",
        "conference_text = ('There is a developer conference' ' happening on 21 July 2019 in London.')\n",
        "conference_doc = nlp(conference_text)\n",
        "# Extract Noun Phrases\n",
        "for chunk in conference_doc.noun_chunks:\n",
        "  print (chunk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a developer conference\n",
            "21 July\n",
            "London\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bJsjg0OCQrg",
        "outputId": "0cb43697-dac9-4c20-f85e-65263bfae596"
      },
      "source": [
        "# Wykrywanie fraz czaskownikowych w tekście\n",
        "\n",
        "about_talk_text = ('The talk will introduce reader about Use'\n",
        "                    ' cases of Natural Language Processing in'\n",
        "                    ' Fintech')\n",
        "pattern = r'(<VERB>?<ADV>*<VERB>+)'\n",
        "about_talk_doc = textacy.make_spacy_doc(about_talk_text, lang='en_core_web_sm')\n",
        "verb_phrases = textacy.extract.pos_regex_matches(about_talk_doc, pattern)\n",
        "# Print all Verb Phrase\n",
        "for chunk in verb_phrases:\n",
        "  print(chunk.text)\n",
        "\n",
        "# Extract Noun Phrase to explain what nouns are involved\n",
        "for chunk in about_talk_doc.noun_chunks:\n",
        "  print (chunk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "will introduce\n",
            "The talk\n",
            "reader\n",
            "Use cases\n",
            "Natural Language Processing\n",
            "Fintech\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/textacy/extract.py:338: DeprecationWarning: `pos_regex_matches()` has been deprecated! for similar but more powerful and performant functionality, use `textacy.extract.matches()` instead.\n",
            "  action=\"once\",\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "7weTCwg8C2qj",
        "outputId": "78b7f547-20a4-4a96-ada9-2f212b722a23"
      },
      "source": [
        "# Znajdowanie nazwanych obiektów w tekście\n",
        "\n",
        "piano_class_text = ('Great Piano Academy is situated'\n",
        "     ' in Mayfair or the City of London and has'\n",
        "     ' world-class piano instructors.')\n",
        "piano_class_doc = nlp(piano_class_text)\n",
        "for ent in piano_class_doc.ents:\n",
        "  print(ent.text, ent.start_char, ent.end_char, ent.label_, spacy.explain(ent.label_))\n",
        "\n",
        "displacy.render(piano_class_doc, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Great Piano Academy 0 19 ORG Companies, agencies, institutions, etc.\n",
            "Mayfair 35 42 GPE Countries, cities, states\n",
            "the City of London 46 64 GPE Countries, cities, states\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Great Piano Academy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is situated in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mayfair\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " or \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the City of London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and has world-class piano instructors.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nCmCW56nDU22",
        "outputId": "f0cb4e01-9c61-47aa-e1f0-0e58877d26e9"
      },
      "source": [
        "# Ukrywanie imion w tekście w oparciu o nazwane obiekty\n",
        "\n",
        "survey_text = ('Out of 5 people surveyed, James Robert,'\n",
        "                ' Julie Fuller and Benjamin Brooks like'\n",
        "                ' apples. Kelly Cox and Matthew Evans'\n",
        "                ' like oranges.')\n",
        "\n",
        "def replace_person_names(token):\n",
        "  if token.ent_iob != 0 and token.ent_type_ == 'PERSON':\n",
        "    return '[CONFIDENTIAL] '\n",
        "  return token.string\n",
        "\n",
        "def redact_names(nlp_doc):\n",
        "  for ent in nlp_doc.ents:\n",
        "    ent.merge()\n",
        "  tokens = map(replace_person_names, nlp_doc)\n",
        "  return ''.join(tokens)\n",
        "\n",
        "survey_doc = nlp(survey_text)\n",
        "redact_names(survey_doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Out of 5 people surveyed, [CONFIDENTIAL] , [CONFIDENTIAL] and [CONFIDENTIAL] like apples. [CONFIDENTIAL] and [CONFIDENTIAL] like oranges.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    }
  ]
}